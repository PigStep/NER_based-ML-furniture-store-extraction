{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PigStep/NER_based-ML-furniture-store-extraction/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#For parsing\n",
        "from urllib.parse import quote\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import json\n",
        "\n",
        "#For modeling\n",
        "from transformers import Trainer, TrainingArguments, AutoModelForTokenClassification, AutoTokenizer\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "m_u03ZmdnlgC"
      },
      "id": "m_u03ZmdnlgC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls_df = pd.read_csv(\"URL_list.csv\")\n",
        "urls_df.head()"
      ],
      "metadata": {
        "id": "MaC8BbQEn1BS"
      },
      "id": "MaC8BbQEn1BS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_series = pd.Series(urls_df[\"max(page)\"]) #To make code easier\n",
        "url_series.head()"
      ],
      "metadata": {
        "id": "pcirfF9sqQO7"
      },
      "id": "pcirfF9sqQO7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing\n",
        "Lets save only opening sites for better processing performace"
      ],
      "metadata": {
        "id": "iPIvcB_ubKy5"
      },
      "id": "iPIvcB_ubKy5"
    },
    {
      "cell_type": "code",
      "source": [
        "def check_is_url_parsing(url):\n",
        "  headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "  try:\n",
        "      response = requests.get(url, headers=headers, timeout=10)\n",
        "      response.raise_for_status() #check for html error\n",
        "      soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "      return True\n",
        "\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Attemp to URL falied: {e}\")\n",
        "    return False"
      ],
      "metadata": {
        "id": "lQxSCYfZbZCn"
      },
      "id": "lQxSCYfZbZCn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_good_urls_csv():\n",
        "  good_urls =[]\n",
        "  for url in url_series:\n",
        "    if(check_is_url_parsing(url)):\n",
        "      good_urls.append(url)\n",
        "\n",
        "  urls = pd.Series(good_urls, name=\"url\")\n",
        "  urls.to_csv(\"ParsingURL_list.csv\")\n",
        "  print(\"Dataset have been created and saved\")"
      ],
      "metadata": {
        "id": "3hfPJV9ebyLM"
      },
      "id": "3hfPJV9ebyLM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create_good_urls_csv()"
      ],
      "metadata": {
        "id": "4Oaa4jjte-Xc"
      },
      "id": "4Oaa4jjte-Xc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate seies with good URLs\n",
        "url_series = pd.read_csv(\"ParsingURL_list.csv\")\n",
        "url_series = pd.Series(url_series[\"url\"])"
      ],
      "metadata": {
        "id": "PrqHvczggBNZ"
      },
      "id": "PrqHvczggBNZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parsing data from sites"
      ],
      "metadata": {
        "id": "WkdZGo1OoO2u"
      },
      "id": "WkdZGo1OoO2u"
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_top_product_names(url, max_length=80, min_length=0, top_n=5):\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    blacklist_tags = {\"footer\", \"nav\", \"script\", \"style\", \"noscript\", \"form\", \"aside\", \"ul\", \"li\"}\n",
        "    candidates = {}\n",
        "\n",
        "    def add_candidate(text, source):\n",
        "        text = text.strip()\n",
        "        if \"$\" in text:\n",
        "          return\n",
        "        if min_length < len(text) <= max_length:\n",
        "            candidates[text] = source\n",
        "\n",
        "    # 1. h1\n",
        "    h1 = soup.find(\"h1\")\n",
        "    if h1:\n",
        "        add_candidate(h1.get_text(), \"h1\")\n",
        "\n",
        "    # 2. h2 Ð¸ h3\n",
        "    for tag in soup.find_all([\"h2\", \"h3\"]):\n",
        "        if tag.find_parent(blacklist_tags): continue\n",
        "        add_candidate(tag.get_text(), tag.name)\n",
        "\n",
        "    # 3. By keywords in class\n",
        "    class_keywords = [\"product__\", \"product-\",\"title\"]\n",
        "    for tag in soup.find_all(True):\n",
        "        classes = tag.get(\"class\")\n",
        "        if not classes:\n",
        "            continue\n",
        "        if any(any(k in cls.lower() for k in class_keywords) for cls in classes):\n",
        "            if tag.find_parent(blacklist_tags): continue\n",
        "            add_candidate(tag.get_text(), f\"class={','.join(classes)}\")\n",
        "\n",
        "    # Longer textes can provide better information\n",
        "    sorted_candidates = sorted(candidates.items(), key=lambda x: len(x[0]), reverse=True)\n",
        "\n",
        "    return sorted_candidates[:top_n]\n"
      ],
      "metadata": {
        "id": "9ZHkdjLg7uFY"
      },
      "id": "9ZHkdjLg7uFY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_list_for_annotations():\n",
        "  with open(\"annote.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    for indx in range(0,100):\n",
        "      url = url_series[indx]\n",
        "\n",
        "      for i, (text, tag) in enumerate(extract_top_product_names(url,max_length=100,top_n=10)):\n",
        "        text = text.replace(\"\\n\",\"\")\n",
        "        file.write(f'[{tag}]: {text}')\n",
        "      file.write('\\n\\n')\n",
        "\n",
        "    print(\"saving complete in 'annote.txt'\")\n",
        "\n",
        "# create_list_for_annotations()"
      ],
      "metadata": {
        "id": "NHdchdU7pbdc"
      },
      "id": "NHdchdU7pbdc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This `annote.txt` file can be used for manual labeling to create `annotations.json` as training file that we will use in future"
      ],
      "metadata": {
        "id": "5JmJrWyoMrpZ"
      },
      "id": "5JmJrWyoMrpZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model fine tuning\n",
        "In my case I will use `bert-base-multilingual-cased` as strong pretrained model. Lets fine tune it by mine manual created dataset"
      ],
      "metadata": {
        "id": "zDUGNXx0zwXD"
      },
      "id": "zDUGNXx0zwXD"
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-multilingual-cased\"\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=3,  # only O, B-PRODUCT, I-PRODUCT\n",
        "    id2label={0: \"O\", 1: \"B-PRODUCT\", 2: \"I-PRODUCT\"},\n",
        "    label2id={\"O\": 0, \"B-PRODUCT\": 1, \"I-PRODUCT\": 2}\n",
        ")"
      ],
      "metadata": {
        "id": "qd9lbcPtG0nX"
      },
      "id": "qd9lbcPtG0nX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "#Load train JSON\n",
        "data = load_data(\"annotations.json\")\n",
        "\n",
        "annotations = data[\"annotations\"]  # Get annotaions list\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def convert_to_iob(text, entities):\n",
        "    tokenized = tokenizer(text, return_offsets_mapping=True, truncation=False)\n",
        "    input_ids = tokenized[\"input_ids\"]\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "    offsets = tokenized[\"offset_mapping\"]\n",
        "\n",
        "    ner_tags = [\"O\"] * len(tokens)\n",
        "\n",
        "    for start_char, end_char, label in entities:\n",
        "        for i, (start_offset, end_offset) in enumerate(offsets):\n",
        "            if start_offset is None or end_offset is None:\n",
        "                continue\n",
        "            #\n",
        "            if start_offset < end_char and end_offset > start_char:\n",
        "                if start_offset == start_char:\n",
        "                    ner_tags[i] = f\"B-{label}\"\n",
        "                else:\n",
        "                    ner_tags[i] = f\"I-{label}\"\n",
        "\n",
        "    return {\"tokens\": tokens, \"ner_tags\": ner_tags}\n"
      ],
      "metadata": {
        "id": "gBDcwm6tz0NT"
      },
      "id": "gBDcwm6tz0NT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = [\"O\", \"B-PRODUCT\", \"I-PRODUCT\"]\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "def tokenize_and_align_labels(example):\n",
        "    tokenized_input = tokenizer(\n",
        "        example[\"tokens\"],\n",
        "        is_split_into_words=True,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    word_ids = tokenized_input.word_ids()\n",
        "    previous_word_idx = None\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "        if word_idx is None:\n",
        "            labels.append(-100)\n",
        "        elif word_idx != previous_word_idx:\n",
        "            labels.append(label2id[example[\"ner_tags\"][word_idx]])\n",
        "        else:\n",
        "            tag = example[\"ner_tags\"][word_idx]\n",
        "            if tag.startswith(\"B-\"):\n",
        "                tag = tag.replace(\"B-\", \"I-\")\n",
        "            labels.append(label2id[tag])\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    tokenized_input[\"labels\"] = labels\n",
        "\n",
        "    # Deleting offset_mapping for model training\n",
        "    tokenized_input.pop(\"offset_mapping\", None)\n",
        "\n",
        "    # returning only needed params\n",
        "    return {\n",
        "        \"input_ids\": tokenized_input[\"input_ids\"],\n",
        "        \"attention_mask\": tokenized_input[\"attention_mask\"],\n",
        "        \"labels\": tokenized_input[\"labels\"]\n",
        "    }\n",
        "\n",
        "\n",
        "processed_data = []\n",
        "for item in annotations:\n",
        "    text = item[0]\n",
        "    entities = item[1].get(\"entities\", [])\n",
        "    if entities:\n",
        "        processed_data.append(convert_to_iob(text, entities))\n",
        "\n",
        "dataset = Dataset.from_list(processed_data)\n",
        "tokenized_dataset = dataset.map(tokenize_and_align_labels).remove_columns(['tokens', 'ner_tags'])"
      ],
      "metadata": {
        "id": "CND26v823jT1"
      },
      "id": "CND26v823jT1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get model metrics"
      ],
      "metadata": {
        "id": "Zxd601vrcGmM"
      },
      "id": "Zxd601vrcGmM"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install seqeval evaluate"
      ],
      "metadata": {
        "id": "Iij6OGCYcl56"
      },
      "id": "Iij6OGCYcl56",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "seqeval = evaluate.load(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_labels = [\n",
        "        [label_list[l] for l in label_row if l != -100]\n",
        "        for label_row in labels\n",
        "    ]\n",
        "    true_predictions = [\n",
        "        [label_list[p] for p, l in zip(pred_row, label_row) if l != -100]\n",
        "        for pred_row, label_row in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"]\n",
        "    }\n"
      ],
      "metadata": {
        "id": "MOUCxjVYcMjs"
      },
      "id": "MOUCxjVYcMjs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_split = tokenized_dataset.train_test_split(test_size=0.2, seed=42) # split 80/20"
      ],
      "metadata": {
        "id": "FMfpdXh_bJe1"
      },
      "id": "FMfpdXh_bJe1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    remove_unused_columns=False\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset_split[\"train\"],\n",
        "    eval_dataset=dataset_split[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "wGyWVhxx4Fu7"
      },
      "id": "wGyWVhxx4Fu7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "Gdxqf-JP48-f"
      },
      "id": "Gdxqf-JP48-f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result of this notebook is a NER model for e-commerce web page PRODUCT classification with metrics:\n",
        "\n",
        "- `'eval_accuracy': 0.839`\n",
        "- `'eval_precision': 0.0`\n",
        "- `'eval_recall': 0.0`\n",
        "- `'eval_f1': 0.0`\n",
        "\n",
        "Despite high accuracy level other metrics are significatly bad for NER classification. This can be a result of bad training dataset labeling, bad parcing pattern providing low value potential for NER entity classification"
      ],
      "metadata": {
        "id": "Avl6wXySJb3L"
      },
      "id": "Avl6wXySJb3L"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model deploying"
      ],
      "metadata": {
        "id": "pZUVuij4n9gw"
      },
      "id": "pZUVuij4n9gw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "script of model deploying is realized in `main.py` script"
      ],
      "metadata": {
        "id": "nmwU71ahodE3"
      },
      "id": "nmwU71ahodE3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "698ad6e9"
      },
      "source": [
        "trainer.save_model(\"product_ner_model\")"
      ],
      "id": "698ad6e9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}